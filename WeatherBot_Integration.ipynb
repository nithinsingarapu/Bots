{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjbSMlZQHbUK",
        "outputId": "2dc1ee48-f2be-4443-c045-211ebe690296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov9'...\n",
            "remote: Enumerating objects: 325, done.\u001b[K\n",
            "remote: Counting objects: 100% (325/325), done.\u001b[K\n",
            "remote: Compressing objects: 100% (152/152), done.\u001b[K\n",
            "remote: Total 325 (delta 165), reused 264 (delta 162), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (325/325), 2.23 MiB | 7.06 MiB/s, done.\n",
            "Resolving deltas: 100% (165/165), done.\n",
            "/content/yolov9\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting telebot\n",
            "  Downloading telebot-0.0.5-py3-none-any.whl (4.8 kB)\n",
            "Collecting pyTelegramBotAPI (from telebot)\n",
            "  Downloading pytelegrambotapi-4.17.0-py3-none-any.whl (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from telebot) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->telebot) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->telebot) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->telebot) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->telebot) (2024.2.2)\n",
            "Installing collected packages: pyTelegramBotAPI, telebot\n",
            "Successfully installed pyTelegramBotAPI-4.17.0 telebot-0.0.5\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/SkalskiP/yolov9.git\n",
        "%cd yolov9\n",
        "!pip install -r requirements.txt -q\n",
        "!pip install telebot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AveDO98N5R2W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f0324fa-c1ea-4494-c7bb-191f60122d70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Received\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/PT/v9Animals.pt'], source=/content/yolov9/saved_images, data=data/coco128.yaml, imgsz=[1280, 1280], conf_thres=0.4, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 1e33dbb Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "gelan-c summary: 467 layers, 25418670 parameters, 0 gradients, 102.5 GFLOPs\n",
            "image 1/1 /content/yolov9/saved_images/259957718_574.jpg: 1280x864 1 chicken, 100.4ms\n",
            "Speed: 1.1ms pre-process, 100.4ms inference, 504.8ms NMS per image at shape (1, 3, 1280, 1280)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n",
            "/content/yolov9/saved_images/259957718_574.jpg\n"
          ]
        }
      ],
      "source": [
        "import telebot\n",
        "import shutil\n",
        "\n",
        "\n",
        "import os\n",
        "import telebot\n",
        "from telebot import types\n",
        "BOT_TOKEN = '7094092093:AAHrwOOL2BWiORsteQ6pMV3bVzmAEK5Vf1A'\n",
        "bot = telebot.TeleBot(BOT_TOKEN)\n",
        "output_folder=\"/content/runs/detect/predict\"\n",
        "@bot.message_handler(content_types=['photo'])\n",
        "def echo_photo(message):\n",
        "    print(\"Image Received\")\n",
        "    # Get the photo ID of the largest available photo\n",
        "    photo = message.photo[-1]\n",
        "    # Download the photo\n",
        "    photo_info = bot.get_file(photo.file_id)\n",
        "    photo_url = f\"https://api.telegram.org/file/bot{BOT_TOKEN}/{photo_info.file_path}\"\n",
        "\n",
        "    # Define the folder where images will be saved\n",
        "    save_folder = \"/content/yolov9/saved_images\"\n",
        "    try:\n",
        "        shutil.rmtree(\"/content/yolov9/saved_images\")\n",
        "        shutil.rmtree(\"/content/yolov9/runs/detect/exp\")\n",
        "        shutil.rmtree(\"/content/yolov9/runs/detect/exp2\")\n",
        "        shutil.rmtree(\"/content/yolov9/runs/detect/exp3\")\n",
        "        #print(f\"Directory '{directory_path}' and its contents have been removed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error while removing directory: {e}\")\n",
        "\n",
        "    if not os.path.exists(save_folder):\n",
        "        os.makedirs(save_folder)\n",
        "\n",
        "    # Define the image filename\n",
        "    image_filename = f\"{message.from_user.id}_{message.message_id}.jpg\"\n",
        "    image_path = os.path.join(save_folder, image_filename)\n",
        "\n",
        "    os.system(f\"wget -O {image_path} {photo_url}\")\n",
        "    !python detect.py \\\n",
        "    --img 1280 --conf 0.4 --device 0 \\\n",
        "    --weights '/content/drive/MyDrive/PT/v9Animals.pt' \\\n",
        "    --source '/content/yolov9/saved_images'\n",
        "\n",
        "    # Send the downloaded photo back to the user\n",
        "    final_image_path = os.path.join(\"/content/yolov9/runs/detect/exp\", image_filename)\n",
        "\n",
        "    with open(final_image_path, 'rb') as photo_file:\n",
        "        print(image_path)\n",
        "        bot.send_photo(message.chat.id, photo_file)\n",
        "\n",
        "    bot.reply_to(message, \"Image saved and sent!\")\n",
        "\n",
        "@bot.message_handler(func=lambda message: True)\n",
        "def handle_text_messages(message):\n",
        "    bot.reply_to(message, \"Please send an image.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    bot.polling(none_stop=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import subprocess\n",
        "import logging\n",
        "\n",
        "# Setup basic logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# Constants for paths and model\n",
        "BASE_FOLDER = \"/content/yolov9\"\n",
        "SAVED_IMAGES_FOLDER = os.path.join(BASE_FOLDER, \"saved_images\")\n",
        "DETECT_FOLDER = os.path.join(BASE_FOLDER, \"runs/detect\")\n",
        "MODEL_WEIGHTS = \"/content/drive/MyDrive/PT/v9Animals.pt\"\n",
        "\n",
        "def clean_directories():\n",
        "    \"\"\"Remove all files and folders within the detect directory to start fresh each time.\"\"\"\n",
        "    shutil.rmtree(DETECT_FOLDER, ignore_errors=True)\n",
        "    os.makedirs(DETECT_FOLDER, exist_ok=True)\n",
        "    os.makedirs(SAVED_IMAGES_FOLDER, exist_ok=True)\n",
        "\n",
        "def detect_objects(image):\n",
        "    \"\"\"Run object detection and return the image with detections and the text results.\"\"\"\n",
        "    clean_directories()\n",
        "    image_path = os.path.join(SAVED_IMAGES_FOLDER, \"input_image.jpg\")\n",
        "    output_image_path = os.path.join(DETECT_FOLDER, \"exp\", \"input_image.jpg\")\n",
        "\n",
        "    # Save the input image\n",
        "    image.save(image_path)\n",
        "\n",
        "    # Run detection model\n",
        "    subprocess.run([\n",
        "        \"python\", \"detect.py\",\n",
        "        \"--img\", \"1280\",\n",
        "        \"--conf\", \"0.4\",\n",
        "        \"--device\", \"0\",\n",
        "        \"--weights\", MODEL_WEIGHTS,\n",
        "        \"--source\", SAVED_IMAGES_FOLDER,\n",
        "        \"--project\", DETECT_FOLDER,\n",
        "        \"--name\", \"exp\",\n",
        "        \"--exist-ok\",\n",
        "        \"--save-txt\"  # Ensure this flag is included\n",
        "    ], check=True)\n",
        "\n",
        "    # Load the processed image\n",
        "    result_image = Image.open(output_image_path) if os.path.exists(output_image_path) else image\n",
        "\n",
        "    # Read detection results\n",
        "    results_path = os.path.join(DETECT_FOLDER, \"exp\", \"labels\", \"input_image.txt\")\n",
        "    detection_results = \"No detections.\"\n",
        "    if os.path.exists(results_path):\n",
        "        with open(results_path, 'r') as file:\n",
        "            detections = file.readlines()\n",
        "        detection_results = \"\".join(detections)\n",
        "\n",
        "    return result_image, detection_results\n",
        "\n",
        "# Setup Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=detect_objects,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=[gr.Image(type=\"pil\"), gr.Textbox(label=\"Detection Results\")],\n",
        "    title=\"YOLOv9 Object Detection\",\n",
        "    description=\"Upload an image to detect objects using YOLOv9.\"\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "2G391nFcknVT",
        "outputId": "b24a8aec-2c0c-4ac1-db2f-6e270170128b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://4cdfa4b73b100c46e9.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4cdfa4b73b100c46e9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kzv8RwC0ymwk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}